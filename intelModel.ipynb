{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intelModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBuOsEibDtrH",
        "colab_type": "code",
        "outputId": "04781b82-dff3-49b1-82a8-bc83b6eea84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "import keras.applications\n",
        "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siN3sHr-GK61",
        "colab_type": "code",
        "outputId": "abcf11ab-3cc2-4f6c-94a4-cba1b2af3ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "# Dataset is stored at Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv5tMOeJEcts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (150, 150, 3)\n",
        "tb_log_dir = 'logs'\n",
        "num_epochs = 2\n",
        "num_classes = 6\n",
        "train_directory = '/content/drive/My Drive/intel-image-classification/seg_train'\n",
        "test_directory = '/content/drive/My Drive/intel-image-classification/seg_test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qypCaxLFO26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear_folder(folder):\n",
        "    if os.path.exists(folder):\n",
        "        for the_file in os.listdir(folder):\n",
        "            file_path = os.path.join(folder, the_file)\n",
        "            try:\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                # elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8EiHcPiXXWI",
        "colab_type": "code",
        "outputId": "45115597-c452-4773-a2c1-cc66ec5bf20f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "\n",
        "import math\n",
        "import random\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path) #Reading the image (OpenCV) in BGR\n",
        "    image = cv2.resize(image,(150,150)) #Resize the image\n",
        "    image = image / 255\n",
        "    #image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # convert to grayscale\n",
        "    return image\n",
        "\n",
        "def augment_image(images):\n",
        "    seq = iaa.Sequential([\n",
        "      iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen), cropped pixels are set black\n",
        "      iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
        "      iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
        "    ])\n",
        "    images_aug = seq(images=images)\n",
        "    return images_aug\n",
        "\n",
        "\n",
        "def load_train_val_images(directory, classes, val_split):    \n",
        "    \n",
        "    imagefilepaths = []\n",
        "    imagefilepaths_train = []\n",
        "    imagefilepaths_val = []\n",
        "    y = []\n",
        "\n",
        "    assert(val_split) > 0.0\n",
        "    \n",
        "    # Get file paths\n",
        "    for labels in os.listdir(directory): \n",
        "\n",
        "        if os.path.isdir(os.path.join(directory,labels)): # Only consider folders\n",
        "          \n",
        "          label = classes[labels]\n",
        "          for image_file in os.listdir(directory+ '/' + labels):\n",
        "              imagefilepaths.append(directory+ '/' + labels+'/'+image_file)\n",
        "              y.append(label)\n",
        "\n",
        "    # Shuffle before loading images is more efficient\n",
        "    zipped = list(zip(imagefilepaths, y))\n",
        "    random.shuffle(zipped)\n",
        "    imagefilepaths, y = zip(*zipped)\n",
        "\n",
        "    # Split into test and validation split\n",
        "    split_idx = math.floor(val_split * len(imagefilepaths))\n",
        "    imagefilepaths_val = imagefilepaths[:split_idx]\n",
        "    valy = np.array(y[:split_idx]) \n",
        "    imagefilepaths_train = imagefilepaths[split_idx:]\n",
        "    trainy = np.array(y[split_idx:]) \n",
        "\n",
        "    # RAM reasons\n",
        "    imagefilepaths = None\n",
        "    y = None\n",
        "    trainx = []\n",
        "    valx = []\n",
        "  \n",
        "    \n",
        "    for i, image_path in enumerate(imagefilepaths_train):\n",
        "        image = preprocess_image(image_path)\n",
        "        trainx.append(image)\n",
        "        if i % 1000 == 999 :\n",
        "            print('Preprocessing train image ' + str(i) + ' of ' + str(len(imagefilepaths_train)))\n",
        "\n",
        "    for i,image_path in enumerate(imagefilepaths_val):\n",
        "        image = preprocess_image(image_path)\n",
        "        valx.append(image)\n",
        "        if i % 1000 == 999:\n",
        "            print('Preprocessing val image ' + str(i) + ' of ' + str(len(imagefilepaths_val)))\n",
        "\n",
        "    #TODO: add image augmentation\n",
        "    np.array(trainx)\n",
        "    trainx = augment_image(trainx)\n",
        "\n",
        "    return trainx, trainy, np.array(valx), valy\n",
        "\n",
        "def load_test_images(directory, classes):\n",
        "    testx = []\n",
        "    testy = [] \n",
        "\n",
        "\n",
        "    for labels in os.listdir(directory):  \n",
        "\n",
        "      if os.path.isdir(os.path.join(directory,labels)): # Only consider folders\n",
        "        label = classes[labels]\n",
        "        print(labels)\n",
        "\n",
        "        for image_file in os.listdir(directory+ '/' + labels): #Extracting the file name of the image from Class Label folder\n",
        "            image = preprocess_image(directory+ '/' + labels + '/' + image_file)\n",
        "            testx.append(image)\n",
        "            testy.append(label)\n",
        "  \n",
        "\n",
        "    return testx, testy\n",
        "\n",
        "classes = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}\n",
        "reverse_classes = {'glacier':2, 'sea':4, 'buildings':0, 'forest':1, 'street':5, 'mountain':3}\n",
        "\n",
        "xtrain, ytrain, xval, yval = load_train_val_images(train_directory, reverse_classes, 0.25)\n",
        "np.save(train_directory+ '/trainxdata2.npy', xtrain)\n",
        "np.save(train_directory+ '/trainydata2.npy', ytrain)\n",
        "np.save(train_directory+ '/valxdata2.npy', xval)\n",
        "np.save(train_directory+ '/valydata2.npy', yval)\n",
        "xtest, ytest = load_test_images(test_directory, reverse_classes)\n",
        "np.save(test_directory+ '/testxdata2.npy', xtest)\n",
        "np.save(test_directory+ '/testydata2.npy', ytest)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing train image 999 of 10542\n",
            "Preprocessing train image 1999 of 10542\n",
            "Preprocessing train image 2999 of 10542\n",
            "Preprocessing train image 3999 of 10542\n",
            "Preprocessing train image 4999 of 10542\n",
            "Preprocessing train image 5999 of 10542\n",
            "Preprocessing train image 6999 of 10542\n",
            "Preprocessing train image 7999 of 10542\n",
            "Preprocessing train image 8999 of 10542\n",
            "Preprocessing train image 9999 of 10542\n",
            "Preprocessing val image 999 of 3514\n",
            "Preprocessing val image 1999 of 3514\n",
            "Preprocessing val image 2999 of 3514\n",
            "sea\n",
            "mountain\n",
            "street\n",
            "glacier\n",
            "forest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2L1XMXUFUqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "\n",
        "    basemodel = keras.applications.vgg16.VGG16(\n",
        "        input_shape=img_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        pooling='avg')\n",
        "\n",
        "    #for layer in basemodel.layers:\n",
        "    #    layer.trainable = False\n",
        "\n",
        "    basemodel.summary()\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(basemodel)\n",
        "    '''\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), input_shape =img_shape, padding='same', activation='relu'))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, kernel_size = (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    '''\n",
        "    model.add(Dense(4096, activation= 'relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1028, activation= 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnpnNq-eFYb-",
        "colab_type": "code",
        "outputId": "68fdd890-29db-42ac-d3b4-ed1153bfa9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "seed = 42\n",
        "batch_size = 32\n",
        "\n",
        "xtrain = np.load(train_directory+ '/trainxdata2.npy') \n",
        "ytrain = np.load(train_directory+ '/trainydata2.npy')\n",
        "xval = np.load(train_directory+ '/valxdata2.npy')\n",
        "yval = np.load(train_directory+ '/valydata2.npy')\n",
        "xtest = np.load(test_directory+ '/testxdata2.npy')\n",
        "ytest = np.load(test_directory+ '/testydata2.npy')\n",
        "\n",
        "ytrain = keras.utils.to_categorical(ytrain)\n",
        "ytest = keras.utils.to_categorical(ytest)\n",
        "\n",
        "'''# different pipeline needed, because reading images from google drive is really really slow\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    data_format='channels_last',\n",
        "    validation_split=0.25,\n",
        "    #shear_range=0.2,\n",
        "    #zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_directory,\n",
        "    target_size=img_shape[:-1], # only height and width\n",
        "    batch_size=batch_size,\n",
        "    seed=seed,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    color_mode='rgb')\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_directory,\n",
        "    target_size=img_shape[:-1], # only height and width\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb')\n",
        "\n",
        "validation_data = train_datagen.flow_from_directory(\n",
        "    train_directory, # same directory as training data\n",
        "    target_size=img_shape[:-1],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    subset='validation') # set as validation data'''\n",
        "\n",
        "\n",
        "\n",
        "clear_folder(tb_log_dir)\n",
        "tensorboard = TensorBoard(log_dir=tb_log_dir)\n",
        "checkpoint = ModelCheckpoint(train_directory+ 'weights.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model = build_model()\n",
        "optimizer = optimizers.RMSprop(lr=1e-4)\n",
        "# Labels are one hot encoded\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "print(model.summary)\n",
        "\n",
        "model.fit(xtrain, ytrain, epochs=15, batch_size=32, validation_data =(xval, yval), shuffle=True, callbacks=[tensorboard, checkpoint])\n",
        "prediction = model.predict(xtest)\n",
        "\n",
        "\n",
        "#class_labels = list(reverse_classes.keys())   \n",
        "\n",
        "#confusion = metrics.classification_report(np.argmax(ytest, axis = 1), prediction, target_names=class_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 15,110,214\n",
            "Trainable params: 395,526\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7fcb25f1c128>>\n",
            "Train on 10542 samples, validate on 3514 samples\n",
            "Epoch 1/15\n",
            "10542/10542 [==============================] - 34s 3ms/step - loss: 1.4454 - acc: 0.7563 - val_loss: 9.6639 - val_acc: 0.3256\n",
            "Epoch 2/15\n",
            "   64/10542 [..............................] - ETA: 25s - loss: 0.4960 - acc: 0.8125"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:707: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10542/10542 [==============================] - 34s 3ms/step - loss: 0.5557 - acc: 0.8604 - val_loss: 9.5382 - val_acc: 0.3372\n",
            "Epoch 3/15\n",
            "10542/10542 [==============================] - 34s 3ms/step - loss: 0.3943 - acc: 0.8815 - val_loss: 9.7032 - val_acc: 0.3261\n",
            "Epoch 4/15\n",
            "10542/10542 [==============================] - 34s 3ms/step - loss: 0.3348 - acc: 0.8930 - val_loss: 9.8843 - val_acc: 0.3381\n",
            "Epoch 5/15\n",
            " 8192/10542 [======================>.......] - ETA: 5s - loss: 0.3135 - acc: 0.9016"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ae56f4e092e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}