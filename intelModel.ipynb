{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intelModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBuOsEibDtrH",
        "colab_type": "code",
        "outputId": "057f4e2e-4b50-4274-8536-c59f7984ff84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "import keras.applications\n",
        "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siN3sHr-GK61",
        "colab_type": "code",
        "outputId": "c05c566d-0fd1-49bc-fbdf-99fbecef8856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "# Dataset is stored at Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv5tMOeJEcts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (150, 150, 3)\n",
        "tb_log_dir = 'logs'\n",
        "num_epochs = 2\n",
        "num_classes = 6\n",
        "train_directory = '/content/drive/My Drive/intel-image-classification/seg_train'\n",
        "test_directory = '/content/drive/My Drive/intel-image-classification/seg_test'\n",
        "classes = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}\n",
        "reverse_classes = {'glacier':2, 'sea':4, 'buildings':0, 'forest':1, 'street':5, 'mountain':3}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qypCaxLFO26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear_folder(folder):\n",
        "    if os.path.exists(folder):\n",
        "        for the_file in os.listdir(folder):\n",
        "            file_path = os.path.join(folder, the_file)\n",
        "            try:\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                # elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8EiHcPiXXWI",
        "colab_type": "code",
        "outputId": "45115597-c452-4773-a2c1-cc66ec5bf20f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "\n",
        "import math\n",
        "import random\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path) #Reading the image (OpenCV) in BGR\n",
        "    image = cv2.resize(image,(150,150)) #Resize the image\n",
        "    image = image / 255\n",
        "    #image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # convert to grayscale\n",
        "    return image\n",
        "\n",
        "def augment_image(images):\n",
        "    seq = iaa.Sequential([\n",
        "      iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen), cropped pixels are set black\n",
        "      iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
        "      iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
        "    ])\n",
        "    images_aug = seq(images=images)\n",
        "    return images_aug\n",
        "\n",
        "\n",
        "def load_train_val_images(directory, classes, val_split):    \n",
        "    \n",
        "    imagefilepaths = []\n",
        "    imagefilepaths_train = []\n",
        "    imagefilepaths_val = []\n",
        "    y = []\n",
        "\n",
        "    assert(val_split) > 0.0\n",
        "    \n",
        "    # Get file paths\n",
        "    for labels in os.listdir(directory): \n",
        "\n",
        "        if os.path.isdir(os.path.join(directory,labels)): # Only consider folders\n",
        "          \n",
        "          label = classes[labels]\n",
        "          for image_file in os.listdir(directory+ '/' + labels):\n",
        "              imagefilepaths.append(directory+ '/' + labels+'/'+image_file)\n",
        "              y.append(label)\n",
        "\n",
        "    # Shuffle before loading images is more efficient\n",
        "    zipped = list(zip(imagefilepaths, y))\n",
        "    random.shuffle(zipped)\n",
        "    imagefilepaths, y = zip(*zipped)\n",
        "\n",
        "    # Split into test and validation split\n",
        "    split_idx = math.floor(val_split * len(imagefilepaths))\n",
        "    imagefilepaths_val = imagefilepaths[:split_idx]\n",
        "    valy = np.array(y[:split_idx]) \n",
        "    imagefilepaths_train = imagefilepaths[split_idx:]\n",
        "    trainy = np.array(y[split_idx:]) \n",
        "\n",
        "    # RAM reasons\n",
        "    imagefilepaths = None\n",
        "    y = None\n",
        "    trainx = []\n",
        "    valx = []\n",
        "  \n",
        "    \n",
        "    for i, image_path in enumerate(imagefilepaths_train):\n",
        "        image = preprocess_image(image_path)\n",
        "        trainx.append(image)\n",
        "        if i % 1000 == 999 :\n",
        "            print('Preprocessing train image ' + str(i) + ' of ' + str(len(imagefilepaths_train)))\n",
        "\n",
        "    for i,image_path in enumerate(imagefilepaths_val):\n",
        "        image = preprocess_image(image_path)\n",
        "        valx.append(image)\n",
        "        if i % 1000 == 999:\n",
        "            print('Preprocessing val image ' + str(i) + ' of ' + str(len(imagefilepaths_val)))\n",
        "\n",
        "    #TODO: add image augmentation\n",
        "    np.array(trainx)\n",
        "    trainx = augment_image(trainx)\n",
        "\n",
        "    return trainx, trainy, np.array(valx), valy\n",
        "\n",
        "def load_test_images(directory, classes):\n",
        "    testx = []\n",
        "    testy = [] \n",
        "\n",
        "\n",
        "    for labels in os.listdir(directory):  \n",
        "\n",
        "      if os.path.isdir(os.path.join(directory,labels)): # Only consider folders\n",
        "        label = classes[labels]\n",
        "        print(labels)\n",
        "\n",
        "        for image_file in os.listdir(directory+ '/' + labels): #Extracting the file name of the image from Class Label folder\n",
        "            image = preprocess_image(directory+ '/' + labels + '/' + image_file)\n",
        "            testx.append(image)\n",
        "            testy.append(label)\n",
        "  \n",
        "\n",
        "    return testx, testy\n",
        "\n",
        "xtrain, ytrain, xval, yval = load_train_val_images(train_directory, reverse_classes, 0.25)\n",
        "np.save(train_directory+ '/trainxdata2.npy', xtrain)\n",
        "np.save(train_directory+ '/trainydata2.npy', ytrain)\n",
        "np.save(train_directory+ '/valxdata2.npy', xval)\n",
        "np.save(train_directory+ '/valydata2.npy', yval)\n",
        "xtest, ytest = load_test_images(test_directory, reverse_classes)\n",
        "np.save(test_directory+ '/testxdata2.npy', xtest)\n",
        "np.save(test_directory+ '/testydata2.npy', ytest)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing train image 999 of 10542\n",
            "Preprocessing train image 1999 of 10542\n",
            "Preprocessing train image 2999 of 10542\n",
            "Preprocessing train image 3999 of 10542\n",
            "Preprocessing train image 4999 of 10542\n",
            "Preprocessing train image 5999 of 10542\n",
            "Preprocessing train image 6999 of 10542\n",
            "Preprocessing train image 7999 of 10542\n",
            "Preprocessing train image 8999 of 10542\n",
            "Preprocessing train image 9999 of 10542\n",
            "Preprocessing val image 999 of 3514\n",
            "Preprocessing val image 1999 of 3514\n",
            "Preprocessing val image 2999 of 3514\n",
            "sea\n",
            "mountain\n",
            "street\n",
            "glacier\n",
            "forest\n",
            "buildings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2L1XMXUFUqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "\n",
        "    basemodel = keras.applications.vgg16.VGG16(\n",
        "        input_shape=img_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        pooling='avg')\n",
        "\n",
        "    #for layer in basemodel.layers:\n",
        "    #    layer.trainable = False\n",
        "\n",
        "    basemodel.summary()\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(basemodel)\n",
        "    '''\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), input_shape =img_shape, padding='same', activation='relu'))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, kernel_size = (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    '''\n",
        "    model.add(Dense(2048, activation= 'relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(512, activation= 'relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnpnNq-eFYb-",
        "colab_type": "code",
        "outputId": "5a372365-aa06-45e6-9e44-b19606d87d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "seed = 42\n",
        "batch_size = 32\n",
        "\n",
        "xtrain = np.load(train_directory+ '/trainxdata2.npy') \n",
        "ytrain = np.load(train_directory+ '/trainydata2.npy')\n",
        "xval = np.load(train_directory+ '/valxdata2.npy')\n",
        "yval = np.load(train_directory+ '/valydata2.npy')\n",
        "xtest = np.load(test_directory+ '/testxdata2.npy')\n",
        "ytest = np.load(test_directory+ '/testydata2.npy')\n",
        "\n",
        "print(xtrain.shape)\n",
        "\n",
        "ytrain = keras.utils.to_categorical(ytrain)\n",
        "yval = keras.utils.to_categorical(yval)\n",
        "ytest = keras.utils.to_categorical(ytest)\n",
        "\n",
        "'''# different pipeline needed, because reading images from google drive is really really slow\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    data_format='channels_last',\n",
        "    validation_split=0.25,\n",
        "    #shear_range=0.2,\n",
        "    #zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_directory,\n",
        "    target_size=img_shape[:-1], # only height and width\n",
        "    batch_size=batch_size,\n",
        "    seed=seed,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    color_mode='rgb')\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_directory,\n",
        "    target_size=img_shape[:-1], # only height and width\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb')\n",
        "\n",
        "validation_data = train_datagen.flow_from_directory(\n",
        "    train_directory, # same directory as training data\n",
        "    target_size=img_shape[:-1],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    subset='validation') # set as validation data'''\n",
        "\n",
        "\n",
        "\n",
        "clear_folder(tb_log_dir)\n",
        "tensorboard = TensorBoard(log_dir=tb_log_dir)\n",
        "checkpoint = ModelCheckpoint(train_directory+ 'weights.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model = build_model()\n",
        "optimizer = optimizers.RMSprop(lr=2e-5)\n",
        "# Labels are one hot encoded\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "print(model.summary)\n",
        "\n",
        "model.fit(xtrain, ytrain, epochs=5, batch_size=32, validation_data =(xval, yval), shuffle=True, callbacks=[tensorboard, checkpoint])\n",
        "\n",
        "prediction = model.predict(xtest)\n",
        "\n",
        "\n",
        "class_labels = list(reverse_classes.keys())   \n",
        "\n",
        "confusion = confusion_matrix(np.argmax(ytest, axis = 1), prediction, target_names=class_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10542, 150, 150, 3)\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2048)              1050624   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 6)                 3078      \n",
            "=================================================================\n",
            "Total params: 16,817,478\n",
            "Trainable params: 16,817,478\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7fead6095f60>>\n",
            "Train on 10542 samples, validate on 3514 samples\n",
            "Epoch 1/5\n",
            "10542/10542 [==============================] - 47s 4ms/step - loss: 0.7430 - acc: 0.7141 - val_loss: 0.5212 - val_acc: 0.8125\n",
            "Epoch 2/5\n",
            "   32/10542 [..............................] - ETA: 40s - loss: 0.6708 - acc: 0.6875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:707: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10542/10542 [==============================] - 46s 4ms/step - loss: 0.3855 - acc: 0.8638 - val_loss: 0.4206 - val_acc: 0.8645\n",
            "Epoch 3/5\n",
            "10542/10542 [==============================] - 46s 4ms/step - loss: 0.3099 - acc: 0.8923 - val_loss: 0.3845 - val_acc: 0.8802\n",
            "Epoch 4/5\n",
            "10542/10542 [==============================] - 46s 4ms/step - loss: 0.2612 - acc: 0.9113 - val_loss: 0.2656 - val_acc: 0.9183\n",
            "Epoch 5/5\n",
            "10542/10542 [==============================] - 46s 4ms/step - loss: 0.2210 - acc: 0.9246 - val_loss: 0.3717 - val_acc: 0.8779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf2b3080a188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
          ]
        }
      ]
    }
  ]
}