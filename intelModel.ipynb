{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intelModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBuOsEibDtrH",
        "colab_type": "code",
        "outputId": "04781b82-dff3-49b1-82a8-bc83b6eea84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "import keras.applications\n",
        "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siN3sHr-GK61",
        "colab_type": "code",
        "outputId": "abcf11ab-3cc2-4f6c-94a4-cba1b2af3ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "# Dataset is stored at Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv5tMOeJEcts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (150, 150, 3)\n",
        "tb_log_dir = 'logs'\n",
        "num_epochs = 2\n",
        "num_classes = 6\n",
        "train_directory = '/content/drive/My Drive/intel-image-classification/seg_train'\n",
        "test_directory = '/content/drive/My Drive/intel-image-classification/seg_test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qypCaxLFO26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear_folder(folder):\n",
        "    if os.path.exists(folder):\n",
        "        for the_file in os.listdir(folder):\n",
        "            file_path = os.path.join(folder, the_file)\n",
        "            try:\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                # elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8EiHcPiXXWI",
        "colab_type": "code",
        "outputId": "45115597-c452-4773-a2c1-cc66ec5bf20f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "\n",
        "import math\n",
        "import random\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path) #Reading the image (OpenCV) in BGR\n",
        "    image = cv2.resize(image,(150,150)) #Resize the image\n",
        "    image = image / 255\n",
        "    #image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # convert to grayscale\n",
        "    return image\n",
        "\n",
        "def augment_image(images):\n",
        "    seq = iaa.Sequential([\n",
        "      iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen), cropped pixels are set black\n",
        "      iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
        "      iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
        "    ])\n",
        "    images_aug = seq(images=images)\n",
        "    return images_aug\n",
        "\n",
        "\n",
        "def load_train_val_images(directory, classes, val_split):    \n",
        "    \n",
        "    imagefilepaths = []\n",
        "    imagefilepaths_train = []\n",
        "    imagefilepaths_val = []\n",
        "    y = []\n",
        "\n",
        "    assert(val_split) > 0.0\n",
        "    \n",
        "    # Get file paths\n",
        "    for labels in os.listdir(directory): \n",
        "\n",
        "        if os.path.isdir(os.path.join(directory,labels)): # Only consider folders\n",
        "          \n",
        "          label = classes[labels]\n",
        "          for image_file in os.listdir(directory+ '/' + labels):\n",
        "              imagefilepaths.append(directory+ '/' + labels+'/'+image_file)\n",
        "              y.append(label)\n",
        "\n",
        "    # Shuffle before loading images is more efficient\n",
        "    zipped = list(zip(imagefilepaths, y))\n",
        "    random.shuffle(zipped)\n",
        "    imagefilepaths, y = zip(*zipped)\n",
        "\n",
        "    # Split into test and validation split\n",
        "    split_idx = math.floor(val_split * len(imagefilepaths))\n",
        "    imagefilepaths_val = imagefilepaths[:split_idx]\n",
        "    valy = np.array(y[:split_idx]) \n",
        "    imagefilepaths_train = imagefilepaths[split_idx:]\n",
        "    trainy = np.array(y[split_idx:]) \n",
        "\n",
        "    # RAM reasons\n",
        "    imagefilepaths = None\n",
        "    y = None\n",
        "    trainx = []\n",
        "    valx = []\n",
        "  \n",
        "    \n",
        "    for i, image_path in enumerate(imagefilepaths_train):\n",
        "        image = preprocess_image(image_path)\n",
        "        trainx.append(image)\n",
        "        if i % 1000 == 999 :\n",
        "            print('Preprocessing train image ' + str(i) + ' of ' + str(len(imagefilepaths_train)))\n",
        "\n",
        "    for i,image_path in enumerate(imagefilepaths_val):\n",
        "        image = preprocess_image(image_path)\n",
        "        valx.append(image)\n",
        "        if i % 1000 == 999:\n",
        "            print('Preprocessing val image ' + str(i) + ' of ' + str(len(imagefilepaths_val)))\n",
        "\n",
        "    #TODO: add image augmentation\n",
        "    np.array(trainx)\n",
        "    trainx = augment_image(trainx)\n",
        "\n",
        "    return trainx, trainy, np.array(valx), valy\n",
        "\n",
        "def load_test_images(directory, classes):\n",
        "    testx = []\n",
        "    testy = [] \n",
        "\n",
        "\n",
        "    for labels in os.listdir(directory):  \n",
        "\n",
        "      if os.path.isdir(os.path.join(directory,labels)): # Only consider folders\n",
        "        label = classes[labels]\n",
        "        print(labels)\n",
        "\n",
        "        for image_file in os.listdir(directory+ '/' + labels): #Extracting the file name of the image from Class Label folder\n",
        "            image = preprocess_image(directory+ '/' + labels + '/' + image_file)\n",
        "            testx.append(image)\n",
        "            testy.append(label)\n",
        "  \n",
        "\n",
        "    return testx, testy\n",
        "\n",
        "classes = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}\n",
        "reverse_classes = {'glacier':2, 'sea':4, 'buildings':0, 'forest':1, 'street':5, 'mountain':3}\n",
        "\n",
        "xtrain, ytrain, xval, yval = load_train_val_images(train_directory, reverse_classes, 0.25)\n",
        "np.save(train_directory+ '/trainxdata2.npy', xtrain)\n",
        "np.save(train_directory+ '/trainydata2.npy', ytrain)\n",
        "np.save(train_directory+ '/valxdata2.npy', xval)\n",
        "np.save(train_directory+ '/valydata2.npy', yval)\n",
        "xtest, ytest = load_test_images(test_directory, reverse_classes)\n",
        "np.save(test_directory+ '/testxdata2.npy', xtest)\n",
        "np.save(test_directory+ '/testydata2.npy', ytest)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing train image 999 of 10542\n",
            "Preprocessing train image 1999 of 10542\n",
            "Preprocessing train image 2999 of 10542\n",
            "Preprocessing train image 3999 of 10542\n",
            "Preprocessing train image 4999 of 10542\n",
            "Preprocessing train image 5999 of 10542\n",
            "Preprocessing train image 6999 of 10542\n",
            "Preprocessing train image 7999 of 10542\n",
            "Preprocessing train image 8999 of 10542\n",
            "Preprocessing train image 9999 of 10542\n",
            "Preprocessing val image 999 of 3514\n",
            "Preprocessing val image 1999 of 3514\n",
            "Preprocessing val image 2999 of 3514\n",
            "sea\n",
            "mountain\n",
            "street\n",
            "glacier\n",
            "forest\n",
            "buildings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2L1XMXUFUqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "\n",
        "    basemodel = keras.applications.vgg16.VGG16(\n",
        "        input_shape=img_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        pooling='avg')\n",
        "\n",
        "    #for layer in basemodel.layers:\n",
        "    #    layer.trainable = False\n",
        "\n",
        "    basemodel.summary()\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(basemodel)\n",
        "    '''\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), input_shape =img_shape, padding='same', activation='relu'))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, kernel_size = (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    '''\n",
        "    model.add(Dense(4096, activation= 'relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1028, activation= 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnpnNq-eFYb-",
        "colab_type": "code",
        "outputId": "5fafd5eb-79a3-4179-b7e6-72abc18d5dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "seed = 42\n",
        "batch_size = 32\n",
        "\n",
        "xtrain = np.load(train_directory+ '/trainxdata2.npy') \n",
        "ytrain = np.load(train_directory+ '/trainydata2.npy')\n",
        "xval = np.load(train_directory+ '/valxdata2.npy')\n",
        "yval = np.load(train_directory+ '/valydata2.npy')\n",
        "xtest = np.load(test_directory+ '/testxdata2.npy')\n",
        "ytest = np.load(test_directory+ '/testydata2.npy')\n",
        "\n",
        "print(xtrain.shape)\n",
        "\n",
        "ytrain = keras.utils.to_categorical(ytrain)\n",
        "yval = keras.utils.to_categorical(yval)\n",
        "ytest = keras.utils.to_categorical(ytest)\n",
        "\n",
        "'''# different pipeline needed, because reading images from google drive is really really slow\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    data_format='channels_last',\n",
        "    validation_split=0.25,\n",
        "    #shear_range=0.2,\n",
        "    #zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_directory,\n",
        "    target_size=img_shape[:-1], # only height and width\n",
        "    batch_size=batch_size,\n",
        "    seed=seed,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    color_mode='rgb')\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_directory,\n",
        "    target_size=img_shape[:-1], # only height and width\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb')\n",
        "\n",
        "validation_data = train_datagen.flow_from_directory(\n",
        "    train_directory, # same directory as training data\n",
        "    target_size=img_shape[:-1],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    subset='validation') # set as validation data'''\n",
        "\n",
        "\n",
        "\n",
        "clear_folder(tb_log_dir)\n",
        "tensorboard = TensorBoard(log_dir=tb_log_dir)\n",
        "checkpoint = ModelCheckpoint(train_directory+ 'weights.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model = build_model()\n",
        "optimizer = optimizers.RMSprop(lr=1e-4)\n",
        "# Labels are one hot encoded\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "print(model.summary)\n",
        "\n",
        "model.fit(xtrain, ytrain, epochs=15, batch_size=32, validation_data =(xval, yval), shuffle=True, callbacks=[tensorboard, checkpoint])\n",
        "prediction = model.predict(xtest)\n",
        "\n",
        "\n",
        "#class_labels = list(reverse_classes.keys())   \n",
        "\n",
        "#confusion = metrics.classification_report(np.argmax(ytest, axis = 1), prediction, target_names=class_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10542, 150, 150, 3)\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1028)              4211716   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1028)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 6)                 6174      \n",
            "=================================================================\n",
            "Total params: 21,033,826\n",
            "Trainable params: 21,033,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7f328e478c88>>\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 10542 samples, validate on 3514 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/15\n",
            " 7872/10542 [=====================>........] - ETA: 13s - loss: 1.1327 - acc: 0.5442"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}